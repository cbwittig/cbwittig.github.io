{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "import pandas as pd\n",
    "from zipfile import ZipFile \n",
    "import glob\n",
    "import shutil\n",
    "import io\n",
    "import pandas as pd \n",
    "import csv\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzipping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the zip file name \n",
    "folders = glob.glob('../CRL_pdf/*.zip')\n",
    "d = list()\n",
    "outputdir=\"\"\n",
    "for file_name in folders:   \n",
    "    \n",
    "# file_name = \"../CRL_pdf/CRL_vol.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "    with ZipFile(file_name, 'r') as zip: \n",
    "        # printing all the contents of the zip file \n",
    "        zip.printdir() \n",
    "\n",
    "        # extracting all the files \n",
    "        print('Extracting all the files now...') \n",
    "        zip.extractall() \n",
    "        print('Done!') \n",
    "    zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving pdf files to one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = glob.glob('9*/*.pdf')\n",
    "d = list()\n",
    "outputdir=\"\"\n",
    "for article_file in articles:\n",
    "    shutil.move(article_file, 'PDFfiles')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = glob.glob('10*/*.pdf')\n",
    "d = list()\n",
    "outputdir=\"\"\n",
    "for article_file in articles:\n",
    "    shutil.move(article_file, 'PDFfiles')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting code written for one file to cycle through all pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = glob.glob('PDFfile/*.pdf')\n",
    "d = list()\n",
    "outputdir=\"\"\n",
    "for article_file in articles:\n",
    "    def extract_text_from_pdf(pdf_path):\n",
    "        resource_manager = PDFResourceManager()\n",
    "        fake_file_handle = io.StringIO()\n",
    "        converter = TextConverter(resource_manager, fake_file_handle)\n",
    "        page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "        with open(pdf_path, 'rb') as fh:\n",
    "            for page in PDFPage.get_pages(fh, \n",
    "                                          caching=True,\n",
    "                                          check_extractable=True):\n",
    "                page_interpreter.process_page(page)\n",
    "\n",
    "            text = fake_file_handle.getvalue()\n",
    "\n",
    "        # close open handles\n",
    "        converter.close()\n",
    "        fake_file_handle.close()\n",
    "\n",
    "        if text:\n",
    "            return text\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        file_text=(extract_text_from_pdf(article_file))\n",
    "        print(file_text)\n",
    "        \n",
    "    def ngrams(input, n):\n",
    "        input = input.split(' ')\n",
    "        output = []\n",
    "        for i in range(len(input)-n+1):\n",
    "            output.append(input[i:i+n])\n",
    "        return output\n",
    "    bigram = ngrams(file_text, 2)\n",
    "    df=pd.DataFrame(bigram, columns =['T1', 'T2'])\n",
    "    df2=df.groupby([\"T1\", \"T2\"]).size().reset_index(name='count')\n",
    "    df2.head()\n",
    "    df2.to_csv(article_file)\n",
    "    file_output.write(df2)\n",
    "# article_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
