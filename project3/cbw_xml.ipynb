{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-for-Text-Processing\" data-toc-modified-id=\"Imports-for-Text-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports for Text Processing</a></span></li><li><span><a href=\"#ITERATING-OVER-DIRECTORY-OF-XML-FILES-~-PRINT-TO-SCREEN-\" data-toc-modified-id=\"ITERATING-OVER-DIRECTORY-OF-XML-FILES-~-PRINT-TO-SCREEN--2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ITERATING OVER DIRECTORY OF XML FILES ~ PRINT TO SCREEN </a></span></li><li><span><a href=\"#CODE-FOR-ALERT-BOX-HEADERS\" data-toc-modified-id=\"CODE-FOR-ALERT-BOX-HEADERS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CODE FOR ALERT BOX HEADERS</a></span></li><li><span><a href=\"#-\" data-toc-modified-id=\"--4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span> </a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong><center><h2>Imports for Text Processing</h2></center></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2 #processes PDF files\n",
    "import re  #regex for advanced searching - regular expressions package\n",
    "import nltk #natural language toolkit\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import functools\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style\n",
    "\n",
    "#XML parsing for reading XML into dataframes\n",
    "import xml.etree.ElementTree as et\n",
    "import xmltodict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong><center><h2>ITERATING OVER DIRECTORY OF XML FILES ~ PRINT TO SCREEN </h2></center></strong>\n",
    "    <p>https://gokhanatil.com/2017/11/python-for-data-science-importing-xml-to-pandas-dataframe.html</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rq', '33', '2', '1993']\n"
     ]
    }
   ],
   "source": [
    "#Read single xml file in and save to csv with columns for journal title, volume, issue, and year.\n",
    "\n",
    "tree = et.parse(\"test.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "f = open('test.csv', 'w')\n",
    "\n",
    "csvwriter = csv.writer(f)\n",
    "\n",
    "count = 0\n",
    "\n",
    "head = ['journal_title', 'journal_volume', 'journal_issue', 'journal_date']\n",
    "\n",
    "csvwriter.writerow(head)\n",
    "\n",
    "for item in root.findall('front'):\n",
    "    row = []\n",
    "    journal_title = item.find('journal-meta').find('journal-id').text\n",
    "    row.append(journal_title)\n",
    "    \n",
    "    journal_volume = item.find('article-meta').find('volume').text\n",
    "    row.append(journal_volume)\n",
    "    \n",
    "    journal_issue = item.find('article-meta').find('issue').text\n",
    "    row.append(journal_issue)\n",
    "    \n",
    "    journal_date = item.find('article-meta').find('pub-date').find('year').text\n",
    "    row.append(journal_date)\n",
    "    \n",
    "    print(row)\n",
    "    \n",
    "csvwriter.writerow(row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xml_smalltest\\\\journal-article-10.2307_20862402.xml', 'rq', '33', '2', '1993']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20862465.xml', 'rq', '33', '3', '1994']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20862587.xml', 'rq', '34', '1', '1994']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20862879.xml', 'rq', '35', '2', '1995']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20862899.xml', 'rq', '35', '2', '1995']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20863466.xml', 'refuseserq', '38', '1', '1998']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20864119.xml', 'refuseserq', '43', '1', '2003']\n",
      "['xml_smalltest\\\\journal-article-10.2307_20864428.xml', 'refuseserq', '44', '4', '2005']\n"
     ]
    }
   ],
   "source": [
    "#SAMPLE CODE TO TRY TO ITERATE OVER XML DIRECTORY PRINT TO SCREEN -- SAVE TO CSV\n",
    "\n",
    "path = \"xml_smalltest\"\n",
    "filenames=[]\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if not filename.endswith('.xml'):\n",
    "        continue\n",
    "    fullname = os.path.join(path,filename)\n",
    "    filenames.append(fullname)\n",
    "    \n",
    "# print(filenames)\n",
    "\n",
    "csvfile = open('xmltest_small.csv', 'w')\n",
    "csv_writer = csv.writer(csvfile)\n",
    "\n",
    "for filename in filenames:\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    row = []\n",
    "    row.append(filename)\n",
    "    \n",
    "    for file in root.iter('front'):\n",
    "    \n",
    "        for item in root.findall('front'):\n",
    "\n",
    "            journal_title = item.find('journal-meta').find('journal-id').text\n",
    "            row.append(journal_title)\n",
    "\n",
    "            journal_volume = item.find('article-meta').find('volume').text\n",
    "            row.append(journal_volume)\n",
    "\n",
    "            journal_issue = item.find('article-meta').find('issue').text\n",
    "            row.append(journal_issue)\n",
    "\n",
    "            journal_date = item.find('article-meta').find('pub-date').find('year').text\n",
    "            row.append(journal_date)\n",
    "            \n",
    "\n",
    "            print(row)\n",
    "\n",
    "head = ['filename', 'journal_title', 'journal_volume', 'journal_issue', 'journal_date']\n",
    "\n",
    "csv_writer.writerow(head)\n",
    "csv_writer.writerow(row)\n",
    "csvfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rq 33 2 1993\n",
      "rq 33 3 1994\n",
      "rq 34 1 1994\n",
      "rq 35 2 1995\n",
      "rq 35 2 1995\n",
      "refuseserq 38 1 1998\n",
      "refuseserq 43 1 2003\n",
      "refuseserq 44 4 2005\n"
     ]
    }
   ],
   "source": [
    "#SAMPLE CODE TO TRY TO ITERATE OVER XML DIRECTORY AND PRINT TO SCREEN ONLY\n",
    "path = \"xml_smalltest\"\n",
    "filenames=[]\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if not filename.endswith('.xml'):\n",
    "        continue\n",
    "    fullname = os.path.join(path,filename)\n",
    "    filenames.append(fullname)\n",
    "\n",
    "head = ['journal_title', 'journal_volume', 'journal_issue', 'journal_date']\n",
    "\n",
    "# csvfile = open('xmltest_small.csv', 'w')\n",
    "# csv_writer = csv.writer(csvfile)\n",
    "\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    row = []\n",
    "    \n",
    "    for file in root.iter('front'):\n",
    "    \n",
    "        for item in root.findall('front'):\n",
    "\n",
    "            journal_title = item.find('journal-meta').find('journal-id').text\n",
    "            row.append(journal_title)\n",
    "\n",
    "            journal_volume = item.find('article-meta').find('volume').text\n",
    "            row.append(journal_volume)\n",
    "\n",
    "            journal_issue = item.find('article-meta').find('issue').text\n",
    "            row.append(journal_issue)\n",
    "\n",
    "            journal_date = item.find('article-meta').find('pub-date').find('year').text\n",
    "            row.append(journal_date)\n",
    "            \n",
    "            print(journal_title, journal_volume, journal_issue, journal_date)\n",
    "\n",
    "# csv_writer.writerow(head)\n",
    "# csv_writer.writerow(row)\n",
    "# csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE CODE TO TRY TO ITERATE OVER XML DIRECTORY AND SAVE ALL IN ONE CSV\n",
    "\n",
    "# with open(r'customerdata.csv', 'wb') as f_customerdata:\n",
    "#     csv_customerdata = csv.DictWriter(f_customerdata, fieldnames=fieldnames)\n",
    "#     csv_customerdata.writeheader()\n",
    "\n",
    "# for filename in os.listdir(r'C:\\docs'):\n",
    "#      if not filename.endswith('.xml'): continue\n",
    "#      fullname = os.path.join(r'C:\\docs',filename)\n",
    "#      tree = ET.parse(fullname)\n",
    "#      root = tree.getroot()\n",
    "\n",
    "#      for node in tree.iter('Customer'):\n",
    "#          row = {}\n",
    "#          for field_name, match, cols in fields:\n",
    "#              if cols > 1:\n",
    "#                  for index, el in enumerate(node.findall(match)):\n",
    "#                      try:\n",
    "#                          if index:\n",
    "#                              row[\"{}{}\".format(field_name, index+1)] = el.text\n",
    "#                          else:\n",
    "#                              row[field_name] = el.text\n",
    "\n",
    "#                      except AttributeError as e:\n",
    "#                          row[field_name] = ''\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     row[field_name] = node.find(match).text\n",
    "#                 except AttributeError as e:\n",
    "#                     row[field_name] = ''\n",
    "\n",
    "#        csv_customerdata.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE FOR ALERT BOX HEADERS\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong><center><h2> </h2></center></strong>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
